{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_starter = pd.read_csv(\"ks-projects-201801.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Columns to upper case \n",
    "\n",
    "- Lets convert the columns to uppercase. \n",
    "- For this we will use the `.upper()` method\n",
    "- To do this we need to address only the columns \n",
    "- Start with `kick_starter.columns =`  \n",
    "- Did you get an error? \n",
    "- Hints below if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'NAME', 'CATEGORY', 'MAIN_CATEGORY', 'CURRENCY', 'DEADLINE',\n",
      "       'GOAL', 'LAUNCHED', 'PLEDGED', 'STATE', 'BACKERS', 'COUNTRY',\n",
      "       'USD PLEDGED', 'USD_PLEDGED_REAL', 'USD_GOAL_REAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kick_starter.columns = kick_starter.columns.str.upper()\n",
    "print(kick_starter.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you get an error? \n",
    "\n",
    "The reason we can't simply use `.upper()` on the DataFrame's column names is that \n",
    "- .upper() is a method designed for strings \n",
    "- while DataFrame.columns is an Index object (a collection of strings). \n",
    "  \n",
    "  \n",
    "#### Let's break it down:\n",
    "\n",
    "Why Not .upper() Directly?\n",
    "Data Type Difference:\n",
    "- `df.columns` returns an Index object, not a single string. \n",
    "- The `.upper()` method only works on individual strings \n",
    "- columns are stored in a list-like structure (Index).\n",
    "\n",
    "#### Broadcasting Needed:\n",
    "To apply `.upper()` to each column name, we need to broadcast it over all the column names. <br> \n",
    "Pandas provides the `.str` accessor to handle such operations efficiently.\n",
    "\n",
    "#### Why Use `.str.upper()`?\n",
    "The `.str` accessor in pandas allows us to apply string methods like `.upper()` to each element in the Index object.\n",
    "`.str.upper()` ensures that the transformation applies to all column names in one step, treating them as individual strings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Columns to title case \n",
    "\n",
    "- Start the same way we did above\n",
    "- Rather than `.upper()` we will use `.title()`\n",
    "- What did that do to the columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Name', 'Category', 'Main_Category', 'Currency', 'Deadline',\n",
      "       'Goal', 'Launched', 'Pledged', 'State', 'Backers', 'Country',\n",
      "       'Usd Pledged', 'Usd_Pledged_Real', 'Usd_Goal_Real'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kick_starter.columns = kick_starter.columns.str.title()\n",
    "print(kick_starter.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Similar Methods  \n",
    "\n",
    "1. `str.title()`\n",
    "Capitalizes the first letter of each word in the column names.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.title()\n",
    "    ```\n",
    "    \n",
    "        Example:\n",
    "        \"project_name\" becomes \"Project_Name\"\n",
    "\n",
    "2. `str.lower()`\n",
    "Converts all column names to lowercase.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.lower()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"Project_Name\" becomes \"project_name\"\n",
    "\n",
    "3. `str.upper()`\n",
    "Converts all column names to uppercase.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.upper()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"Project_Name\" becomes \"PROJECT_NAME\"\n",
    "\n",
    "4. `str.strip()`\n",
    "Removes leading and trailing whitespace from column names.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.strip()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \" Project_Name \" becomes \"Project_Name\"\n",
    "\n",
    "5. `str.replace()`\n",
    "Replaces a specific substring in the column names with another string.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.replace('_', ' ')\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"Project_Name\" becomes \"Project Name\"\n",
    "\n",
    "6. `str.contains()` (for filtering columns)\n",
    "(Not for renaming, but useful for selecting columns.)\n",
    "Checks if column names contain a specific substring.\n",
    "\n",
    "    ```js\n",
    "    columns_with_name = kick_starter.columns[kick_starter.columns.str.contains('name')]\n",
    "    print(columns_with_name)\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        Returns column names that include \"name\".\n",
    "\n",
    "7. str.startswith() / str.endswith()\n",
    "Filters columns based on their starting or ending substring.\n",
    "\n",
    "    ```js\n",
    "    // Columns that start with 'proj'\n",
    "    columns_starting_with_proj = kick_starter.columns[kick_starter.columns.str.startswith('proj')]\n",
    "\n",
    "    // Columns that end with 'name'\n",
    "    columns_ending_with_name = kick_starter.columns[kick_starter.columns.str.endswith('name')]\n",
    "    ```\n",
    "\n",
    "8. str.capitalize()\n",
    "Capitalizes the first letter of the first word in each column name.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.capitalize()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"project_name\" becomes \"Project_name\"\n",
    "\n",
    "9. `str.replace()` with regex\n",
    "You can also use regex=True for complex replacements.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.replace(r'\\s+', '_', regex=True)\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        Replaces spaces with underscores.\n",
    "\n",
    "10. Combining Methods\n",
    "You can chain multiple methods together.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = (\n",
    "        kick_starter.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_')\n",
    "    )\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \" Project Name \" becomes \"project_name\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove White Space and Underscores \n",
    "\n",
    "Here we will chain some methods together to accomplish the task.  \n",
    "Our goal is to remove any white space that might be before or after our column names.   \n",
    "Then we will remove underscore and replace them with a space. \n",
    "\n",
    "- Start with `kick_starter.columns =` \n",
    "- Then strip the white space \n",
    "- Then handle replacing the underscore \n",
    "- This should all be ones line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "   kick_starter.columns = (\n",
    "        kick_starter.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping columns We Don't Need \n",
    "\n",
    "### Why Do We Drop Columns in Data Analytics?\n",
    "- **Reduce Noise:** Irrelevant columns can obscure important patterns.\n",
    "\n",
    "- **Improve Efficiency:** Fewer columns mean faster computations.\n",
    "\n",
    "- **Prevent Overfitting:** Reducing irrelevant features helps models generalize better.\n",
    "\n",
    "- **Enhance Clarity:** Simplifies data interpretation and reporting.\n",
    "\n",
    "- **Ensure Privacy:** Removes sensitive or personally identifiable information (PII).\n",
    "\n",
    "- **Avoid Redundancy:** Drops duplicate or highly correlated features.\n",
    "\n",
    "- **Focus on Goals:** Keeps only columns relevant to the analysis objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above in mind let's pick some columns to drop. First we will need to identify some questions and be sure we don't drop columns we don't need. Also we can just infer we may not need certain columns. An example being \"Id\". We have no other data to reference this column with so we can remove it. \n",
    "\n",
    "Things we want to accomplish with our data:\n",
    "- Filter to US only in Country \n",
    "- Goal status for plot \n",
    "- What category has the most backers. \n",
    "- What has the highest backing amount\n",
    "\n",
    "With the above questions we can determine columns to remove. \n",
    "- 'Id' : We can remove this because we can't reference this to anything with our limited data \n",
    "- 'Name' : We will want to keep this so we know what project is what \n",
    "- 'Category' : We will primarily look at Main Category but this could be helpful\n",
    "- 'Main Category' : We have a goal directly related to this column\n",
    "- 'Currency' : We have a goal related to Currency so we will keep this \n",
    "- 'Deadline' : We wont need this column as we have no goals related to this column \n",
    "- 'Goal' : we will keep this as and Usd Goal Real\n",
    "- 'Launched' : We wont need this column as we have no goals related to this column \n",
    "- 'Pledged' : We will keep this and Usd Pledged Real\n",
    "- 'State' :  keep ...\n",
    "- 'Backers' : keep ...\n",
    "- 'Country' : keep ...\n",
    "- 'Usd Pledged' : keep  ...\n",
    "- 'Usd Pledged Real' : keep ...\n",
    "- 'Usd Goal Real' : keep ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list above lest use the `.drop()` method to remove the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop= ['id', 'deadline', 'launched']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Id', 'Deadline', 'Launched'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kick_starter \u001b[38;5;241m=\u001b[39m \u001b[43mkick_starter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcolumns_drop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m kick_starter\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Id', 'Deadline', 'Launched'] not found in axis\""
     ]
    }
   ],
   "source": [
    "kick_starter = kick_starter.drop(columns = columns_drop)\n",
    "kick_starter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address Nulls Remove vs 0 vs Back Fill ect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove Rows with Null Values\n",
    "Use Case: When missing data is sparse or not crucial to the analysis.\n",
    "\n",
    "```python\n",
    "# Drop rows with any NaN values\n",
    "kick_starter_cleaned = kick_starter.dropna()\n",
    "\n",
    "# Drop rows where specific columns have NaN\n",
    "kick_starter_cleaned = kick_starter.dropna(subset=['Column1', 'Column2'])\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- dropna() removes rows where any column has NaN.\n",
    "- subset targets specific columns only.\n",
    "\n",
    "### 2. Fill Nulls with Zero\n",
    "Use Case: When missing values represent quantities like counts or amounts.\n",
    "\n",
    "```python\n",
    "# Fill all NaN values with 0\n",
    "kick_starter_filled = kick_starter.fillna(0)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Filling with 0 ensures calculations like sums are not affected by missing data.\n",
    "\n",
    "### 3. Fill Nulls with a Specific Value\n",
    "Use Case: When missing data should default to a constant like \"Unknown.\"\n",
    "\n",
    "```python\n",
    "# Fill NaN in a specific column with 'Unknown'\n",
    "kick_starter['Category'] = kick_starter['Category'].fillna('Unknown')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- This is useful for categorical columns where missing data can be treated as a new category.\n",
    "\n",
    "### 4. Forward Fill (Use Previous Value)\n",
    "Use Case: For time-series data or when prior values can logically fill gaps.\n",
    "\n",
    "```python\n",
    "# Fill NaN using the previous value in the same column\n",
    "kick_starter_ffill = kick_starter.fillna(method='ffill')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Uses the last valid value to fill the NaN, ideal for propagating information in sequences.\n",
    "\n",
    "\n",
    "### 5. Backward Fill (Use Next Value)\n",
    "Use Case: Similar to forward fill, but uses subsequent values instead.\n",
    "\n",
    "```python\n",
    "# Fill NaN using the next value in the same column\n",
    "kick_starter_bfill = kick_starter.fillna(method='bfill')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Backfills using the next available value, ideal when later data can logically fill gaps.\n",
    "\n",
    "### 6. Fill with Column Mean/Median/Mode\n",
    "Use Case: For numerical data where imputing missing values based on the distribution is valid.\n",
    "\n",
    "```python\n",
    "# Fill NaN with the column mean\n",
    "kick_starter['Amount'] = kick_starter['Amount'].fillna(kick_starter['Amount'].mean())\n",
    "\n",
    "# Fill NaN with the column median\n",
    "kick_starter['Amount'] = kick_starter['Amount'].fillna(kick_starter['Amount'].median())\n",
    "\n",
    "# Fill NaN with the column mode (most frequent value)\n",
    "kick_starter['Category'] = kick_starter['Category'].fillna(kick_starter['Category'].mode()[0])\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- mean and median are for numerical data.\n",
    "- mode is best for categorical data.\n",
    "\n",
    "### 7. Interpolate Missing Values\n",
    "Use Case: For continuous data where missing values can be estimated.\n",
    "\n",
    "```python\n",
    "# Linear interpolation\n",
    "kick_starter_interpolated = kick_starter.interpolate(method='linear')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Interpolates missing values based on surrounding data points. Useful for numerical and time-series data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just going to drop all missing values to keep it \n",
    "- use the `.dropna()` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency    deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP  2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD  2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD  2013-02-26  45000.0   \n",
       "3           Music         Music      USD  2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD  2015-08-29  19500.0   \n",
       "\n",
       "              launched  pledged     state  backers country  usd_pledged  \\\n",
       "0  2015-08-11 12:12:28      0.0    failed        0      GB          0.0   \n",
       "1  2017-09-02 04:43:57   2421.0    failed       15      US        100.0   \n",
       "2  2013-01-12 00:20:50    220.0    failed        3      US        220.0   \n",
       "3  2012-03-17 03:24:11      1.0    failed        1      US          1.0   \n",
       "4  2015-07-04 08:35:03   1283.0  canceled       14      US       1283.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "4            1283.0       19500.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kick_starter_cleaned = kick_starter.dropna()\n",
    "kick_starter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the DataFrame to Include Only US-based Records\n",
    "\n",
    "- **Step 1:** \n",
    "  - Identify the column that contains country information.\n",
    "\n",
    "- **Step 2:** \n",
    "  - Understand the structure of the DataFrame.\n",
    "  - You will need to filter the rows where the value in the \"Country\" column is equal to \"US\" (the United States).\n",
    "\n",
    "- **Step 3:** \n",
    "  - Use a filtering condition.\n",
    "  - You'll want to create a condition that checks if the \"Country\" column contains the value \"US\". This will result in a boolean series (True or False for each row).\n",
    "\n",
    "- **Step 4:** \n",
    "  - Apply the condition to the DataFrame.\n",
    "  - Once you have the condition, apply it to the DataFrame to return only the rows where the condition is true.\n",
    "\n",
    "- **Step 5:** \n",
    "  - Assign the result back to the DataFrame.\n",
    "  - After filtering, ensure you store the filtered DataFrame back into the original variable to update it.\n",
    "\n",
    "- **Tips:**\n",
    "  - Remember, the condition should be based on the value of the \"Country\" column.\n",
    "  - Be careful with case sensitivity (e.g., \"US\" vs \"us\").\n",
    "  - This will be one line of code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kick_starter \u001b[38;5;241m=\u001b[39m kick_starter[\u001b[43mkick_starter\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCountry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m kick_starter\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country'"
     ]
    }
   ],
   "source": [
    "kick_starter = kick_starter[kick_starter['Country'] == \"US\"]\n",
    "kick_starter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Total, Mean, and Median of Backers\n",
    "\n",
    "**Step 1:** Identify the column that contains the number of backers.\n",
    "\n",
    "**Step 2:** Calculate the total number of backers.\n",
    "\n",
    "**Step 3:** Calculate the mean (average) number of backers and round 2 places.\n",
    "\n",
    "**Step 4:** Calculate the median number of backers.\n",
    "\n",
    "**Step 5:** Display the results using print().\n",
    "\n",
    "**Step 6:** Ensure formatting of your print statement more readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of backers is 33089856 the mean of backers is 113.07861543876676 and the median of backers is 14.0\n"
     ]
    }
   ],
   "source": [
    "backers_sum = kick_starter[\"backers\"].sum()\n",
    "backers_mean = kick_starter[\"backers\"].mean()\n",
    "backers_median = kick_starter[\"backers\"].median()\n",
    "\n",
    "print(f\"The sum of backers is {backers_sum} the mean of backers is {backers_mean} and the median of backers is {backers_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Category with the Most Backers\n",
    "\n",
    "**Step 1:** Identify the columns for \"Backers\" and \"Category\".\n",
    "\n",
    "**Step 2:** Group the data by the \"Category\" column.\n",
    "- Use the `groupby()` function to group the data by the \"Category\" column, which will allow you to perform operations on each category.\n",
    "\n",
    "**Step 3:** Sum the backers for each category.\n",
    "- After grouping, apply the `sum()` function to get the total number of backers for each category.\n",
    "\n",
    "**Step 4:** Find the category with the maximum total number of backers.\n",
    "- Use the `idxmax()` function to find the category that has the highest sum of backers.\n",
    "\n",
    "**Step 5:** Display the result.\n",
    "Print out the category with the most backers and the number of backers it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The category with the max backers Tabletop Games\n"
     ]
    }
   ],
   "source": [
    "category_backers = kick_starter.groupby(\"Category\")[\"Backers\"].sum()\n",
    "backers_max = category_backers.idxmax()\n",
    "\n",
    "print(f\" The category with the max backers {backers_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the Categories by Number of Backers in Descending Order\n",
    "\n",
    "**Step 1:** Using the `category_backers` variable.\n",
    "This variable contains the total number of backers for each category, which was previously calculated by grouping the data and summing the backers for each category.\n",
    "\n",
    "**Step 2:** Use the `sort_values()` function to sort the `category_backers`.\n",
    "The sort_values() function is used to sort the values in a Series or DataFrame. You need to specify the ascending parameter to control the order.\n",
    "\n",
    "**Step 3:** Set `ascending=False` to sort in descending order.\n",
    "By setting ascending=False, you will sort the data so that the category with the most backers appears first.\n",
    "\n",
    "**Step 4:** Assign the sorted result back to the `category_backers` variable.\n",
    "Ensure that the sorted result is saved to the same variable so it updates with the new order.\n",
    "\n",
    "**Step 5:** Print the top 10 categories. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Tabletop Games    5105850\n",
       "Product Design    5024566\n",
       "Video Games       3445624\n",
       "Documentary       1277443\n",
       "Hardware           928948\n",
       "Technology         898274\n",
       "Music              797481\n",
       "Gadgets            727234\n",
       "Food               704689\n",
       "Comics             589024\n",
       "Name: backers, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_backers = category_backers.sort_values(ascending=False)\n",
    "category_backers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the last 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Workshops          2638\n",
       "Glass              2153\n",
       "Residencies        2113\n",
       "Literary Spaces    2098\n",
       "Weaving            2074\n",
       "Quilts             1665\n",
       "Couture            1508\n",
       "Crochet             952\n",
       "Embroidery          902\n",
       "Taxidermy           326\n",
       "Name: backers, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_backers.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex groupby and plots\n",
    "\n",
    "This code will only work if install matplotlib and have done your code correct as it uses your variables column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'Usd Pledged Real'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m kick_starter[kick_starter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccessful\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Group by Category and State and sum the specified columns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m top_ten_cats \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mState\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBackers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUsd Pledged Real\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Sort the entire DataFrame by 'Usd Pledged Real' in descending order\u001b[39;00m\n\u001b[1;32m      8\u001b[0m top_ten_cats \u001b[38;5;241m=\u001b[39m top_ten_cats\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsd Pledged Real\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/base.py:239\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mintersection(key)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)):\n\u001b[1;32m    238\u001b[0m         bad_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(bad_keys)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(\u001b[38;5;28mlist\u001b[39m(key), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'Usd Pledged Real'\""
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for successful projects\n",
    "filtered_data = kick_starter[kick_starter['State'] == 'successful']\n",
    "\n",
    "# Group by Category and State and sum the specified columns\n",
    "top_ten_cats = filtered_data.groupby(['Category', 'State'])[['Backers', 'Usd Pledged Real']].sum().reset_index()\n",
    "\n",
    "# Sort the entire DataFrame by 'Usd Pledged Real' in descending order\n",
    "top_ten_cats = top_ten_cats.sort_values(by='Usd Pledged Real', ascending=False)\n",
    "\n",
    "top_ten_cats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_ten_cats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Top 10 Categories by Total Pledged Amount\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m top_pledged \u001b[38;5;241m=\u001b[39m \u001b[43mtop_ten_cats\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsd Pledged Real\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Highlight the highest value in blue, others in light grey\u001b[39;00m\n\u001b[1;32m      9\u001b[0m colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgrey\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(top_pledged))]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_ten_cats' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# 1. Top 10 Categories by Total Pledged Amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_pledged = top_ten_cats.groupby('Category')['Usd Pledged Real'].sum().nlargest(10)\n",
    "\n",
    "# Highlight the highest value in blue, others in light grey\n",
    "colors = ['blue' if i == 0 else 'lightgrey' for i in range(len(top_pledged))]\n",
    "\n",
    "plt.bar(top_pledged.index, top_pledged.values, color=colors)\n",
    "\n",
    "# Add value only on the blue bar (the highest one)\n",
    "plt.text(0, top_pledged.values[0], f'{top_pledged.values[0]:,.0f}', \n",
    "         ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Formatting for x-axis labels and title\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Top 10 Categories by Total Pledged Amount')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total Pledged Amount (USD)')\n",
    "\n",
    "# Add comma formatting for y-axis\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Top 10 Categories by Number of Backers\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_backers = top_ten_cats.groupby('Category')['Backers'].sum().nlargest(10)\n",
    "\n",
    "# Highlight the highest value in blue, others in light grey\n",
    "colors = ['blue' if i == 0 else 'lightgrey' for i in range(len(top_backers))]\n",
    "\n",
    "plt.bar(top_backers.index, top_backers.values, color=colors)\n",
    "\n",
    "# Add value only on the blue bar (the highest one)\n",
    "plt.text(0, top_backers.values[0], f'{top_backers.values[0]:,.0f}', \n",
    "         ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Formatting for x-axis labels and title\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Top 10 Categories by Number of Backers')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Backers')\n",
    "\n",
    "# Add comma formatting for y-axis\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
